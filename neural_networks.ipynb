{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural-networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPy54YQphaUCtRJNGFc6zWf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinyaraujos/machine-learning/blob/activity-3/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQlZBulBLw7P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb1c735b-f3e3-4531-aa91-f6799b9564d8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKfeXtKBL3P3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dcd6908e-8f9f-46ae-a80f-dcd541568c43"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwDwzCNRL5wH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dados = pd.read_csv('/content/drive/My Drive/Colab Notebooks/datasets/heart.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgdO9-LML8ph",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f9d81109-0cad-4389-b2c2-bd856a436fb0"
      },
      "source": [
        "dados.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  exang  oldpeak  slope  ca  thal  target\n",
              "0   63    1   3       145   233    1  ...      0      2.3      0   0     1       1\n",
              "1   37    1   2       130   250    0  ...      0      3.5      0   0     2       1\n",
              "2   41    0   1       130   204    0  ...      0      1.4      2   0     2       1\n",
              "3   56    1   1       120   236    0  ...      0      0.8      2   0     2       1\n",
              "4   57    0   0       120   354    0  ...      1      0.6      2   0     2       1\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRjvxVmjMOkQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#verificar se existem valores NAN, ? ou dados faltantes\n",
        "dados = dados.dropna()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r1UbTaGzSLCg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Re-escala dos dados usando usando máximo e mínimo\n",
        "dados = (dados - dados.min())/(dados.max()-dados.min())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EX0gj5CdS5ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4806fd1a-0781-40ca-9411-49cc6a17eaaf"
      },
      "source": [
        "#dividindo dados em atributos descritores e atributo de classe\n",
        "X = dados.iloc[:,:-1]\n",
        "X.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>145</td>\n",
              "      <td>233</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>150</td>\n",
              "      <td>0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>130</td>\n",
              "      <td>250</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>187</td>\n",
              "      <td>0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>130</td>\n",
              "      <td>204</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>56</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>120</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>178</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>354</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>163</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age  sex  cp  trestbps  chol  fbs  ...  thalach  exang  oldpeak  slope  ca  thal\n",
              "0   63    1   3       145   233    1  ...      150      0      2.3      0   0     1\n",
              "1   37    1   2       130   250    0  ...      187      0      3.5      0   0     2\n",
              "2   41    0   1       130   204    0  ...      172      0      1.4      2   0     2\n",
              "3   56    1   1       120   236    0  ...      178      0      0.8      2   0     2\n",
              "4   57    0   0       120   354    0  ...      163      1      0.6      2   0     2\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjwFhdDtTMBL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "2bf97180-5095-4cbd-a5a9-4cc0abebbb28"
      },
      "source": [
        "y = dados.target\n",
        "y.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1\n",
              "1    1\n",
              "2    1\n",
              "3    1\n",
              "4    1\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpCxlM5fTUZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsMEp72vS_nE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Dividindo a matriz em um conjunto de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCRdoefwTf7C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "4a5f2a84-bf20-44e8-f5d0-97f62c3179a6"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>cp</th>\n",
              "      <th>trestbps</th>\n",
              "      <th>chol</th>\n",
              "      <th>fbs</th>\n",
              "      <th>restecg</th>\n",
              "      <th>thalach</th>\n",
              "      <th>exang</th>\n",
              "      <th>oldpeak</th>\n",
              "      <th>slope</th>\n",
              "      <th>ca</th>\n",
              "      <th>thal</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>135</td>\n",
              "      <td>203</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>132</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>236</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>152</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>150</td>\n",
              "      <td>240</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>222</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>143</td>\n",
              "      <td>1</td>\n",
              "      <td>1.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>135</td>\n",
              "      <td>252</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     age  sex  cp  trestbps  chol  ...  exang  oldpeak  slope  ca  thal\n",
              "63    41    1   1       135   203  ...      0      0.0      1   0     1\n",
              "107   45    0   0       138   236  ...      1      0.2      1   0     2\n",
              "147   60    0   3       150   240  ...      0      0.9      2   0     2\n",
              "66    51    1   2       100   222  ...      1      1.2      1   0     2\n",
              "54    63    0   2       135   252  ...      0      0.0      2   0     2\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylzfSjIATkO6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "768dbe60-4c07-4e10-9cb3-fcf44666dd61"
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "63     1\n",
              "107    1\n",
              "147    1\n",
              "66     1\n",
              "54     1\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxOBkJfnTnQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S60bf1DcTxdk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#definindo modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc6SoWAqT4FB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "e9e39582-0082-43ca-cd6b-4e98a6011c2a"
      },
      "source": [
        "#treinando modelo - lista de parâmetros que podem ser ajustados\n",
        "classificador.fit(X_train,y_train)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='logistic', alpha=0.0001, batch_size='auto',\n",
              "              beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=100, learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjdoDo5cUAKL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "60e98c99-3b26-4760-aad5-9b2db02c5c3d"
      },
      "source": [
        "#realizando classificação\n",
        "classificacao = classificador.predict(X_test)\n",
        "classificacao"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KIBPyjQ4UEpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fi4PGWLUF3g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d8c4322-674a-4c1e-8034-4f80b5ab03c6"
      },
      "source": [
        "#calculando acurácia\n",
        "curacia = accuracy_score(y_test,classificacao)\n",
        "round(curacia,3)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.689"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGK6orAbUWFJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "43d87b63-eb0f-43fb-9e16-0c9fe84b9929"
      },
      "source": [
        "#calculando precisão\n",
        "precisao = precision_score(y_test,classificacao)\n",
        "round(precisao,3)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.595"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZOg4K_mbUrBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando recall (revocação)\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4lLsHctUtNx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2adff0cb-453e-4bc3-bda2-209c33c2d6ec"
      },
      "source": [
        "recall = recall_score(y_test,classificacao)\n",
        "round(recall,3)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.926"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0J5UGK3U2ET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando f1-score\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KlJMVscU5xm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20ec2f84-5379-4d8b-d373-f321be92c31d"
      },
      "source": [
        "f1 = f1_score(y_test,classificacao)\n",
        "round(f1,3)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.725"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7P43jMiwXlTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plotando curva roc - Relação entre falsos positivos e verdadeiro positivo\n",
        "from sklearn.metrics import roc_curve"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvHyE5EsX1q0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr, tpr, _ = roc_curve(y_test,classificacao)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14VYLfJQX46q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b6940e6d-ae90-410b-f7f3-5868e4b0d95c"
      },
      "source": [
        "plt.plot(fpr,tpr,marker='.')\n",
        "plt.title('Curva ROC')\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiro Positivos')\n",
        "plt.show()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZ42g7cfX_bP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#calculando area sob a curva ROC\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfhHD3HXYE98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26fc9941-a2d4-4cc8-99e9-d6599ed9265d"
      },
      "source": [
        "#área da curva - é o resultado da imagem de forma númerica\n",
        "auc = roc_auc_score(y_test,classificacao)\n",
        "round(auc,3)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.713"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjAZAHbMYcoN",
        "colab_type": "text"
      },
      "source": [
        "Validação Cruzada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2nURBB9YIvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# avaliando modelo com cross validation\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_sIAQy7YMVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#define modelo\n",
        "classificador = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRnM22hGYQvv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e7c0f77c-2f4e-4043-8dac-d112e2b4013c"
      },
      "source": [
        "#calculando os scores\n",
        "scores = cross_val_score(classificador,X,y,cv=10)\n",
        "scores"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87096774, 0.83870968, 0.87096774, 0.9       , 0.86666667,\n",
              "       0.8       , 0.83333333, 0.86666667, 0.63333333, 0.76666667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qirfCtMNYTQD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5162f236-21e4-48a3-de90-3f341dc8af70"
      },
      "source": [
        "#Esse modelo têm uma taxa de acerto média de 82,5% com um desvio padrão de 0.074\n",
        "round(scores.mean(),3),round(scores.std(),3)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.825, 0.074)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjzEAtlPYaZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhzMMW45YhTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando árvore\n",
        "arvore = DecisionTreeClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_arvore = cross_val_score(arvore,X,y,cv=10)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAde2oqNYkzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando random forest\n",
        "floresta = RandomForestClassifier()\n",
        "\n",
        "#calculando os scores\n",
        "scores_floresta = cross_val_score(floresta,X,y,cv=10)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yZHdOzLYnZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#criando rede neural\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100),activation='logistic',max_iter=1000)\n",
        "\n",
        "#calculando os scores\n",
        "scores_mlp = cross_val_score(mlp,X,y,cv=10)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4Ahou7UYqEu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f9fe0864-2400-469f-bf10-d46c1c52ebda"
      },
      "source": [
        "#comparação entre os métodos - os resultados da Radom Forest e MLP foram os mesmo em percentual, porém com um desvio padrão diferente.  \n",
        "print('Árvore de Decisão: ', round(scores_arvore.mean(),3),round(scores_arvore.std(),3))\n",
        "print('Random Forest: ', round(scores.mean(),3),round(scores.std(),3))\n",
        "print('MLP:', round(scores_mlp.mean(),3),round(scores_mlp.std(),3))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Árvore de Decisão:  0.788 0.074\n",
            "Random Forest:  0.825 0.074\n",
            "MLP: 0.825 0.079\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-8MMv_IY2NU",
        "colab_type": "text"
      },
      "source": [
        "**Otimização de Parâmetros**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEMVIH4hYy47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Random Search\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQB-XUU6Y7Si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "param_grid = [\n",
        "              {\n",
        "                  'hidden_layer_sizes':  [(10),(50),(100),(50,10),(100,50)],\n",
        "                  'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
        "                  'solver': ['lbfgs', 'sgd', 'adam'],\n",
        "                  'max_iter': [500, 1000, 2000]\n",
        "              }\n",
        "              \n",
        "]"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzspgV4pY_0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = RandomizedSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4kn8kQoZBnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4cf8f8b6-267c-4a1a-dfc3-adfbd7329cfb"
      },
      "source": [
        "#Fazer o treinamento \n",
        "mlp.fit(X,y)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=5, error_score=nan,\n",
              "                   estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                           batch_size='auto', beta_1=0.9,\n",
              "                                           beta_2=0.999, early_stopping=False,\n",
              "                                           epsilon=1e-08,\n",
              "                                           hidden_layer_sizes=(100,),\n",
              "                                           learning_rate='constant',\n",
              "                                           learning_rate_init=0.001,\n",
              "                                           max_fun=15000, max_iter=200,\n",
              "                                           momentum=0.9, n_iter_no_change=10,\n",
              "                                           nesterovs_momentum=True, power_t=0.5,\n",
              "                                           random...\n",
              "                                           verbose=False, warm_start=False),\n",
              "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
              "                   param_distributions=[{'activation': ['identity', 'logistic',\n",
              "                                                        'tanh', 'relu'],\n",
              "                                         'hidden_layer_sizes': [10, 50, 100,\n",
              "                                                                (50, 10),\n",
              "                                                                (100, 50)],\n",
              "                                         'max_iter': [500, 1000, 2000],\n",
              "                                         'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
              "                   return_train_score=False, scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpOalkY7ZXgz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cbe0636a-e979-4420-8378-55d741bb1a71"
      },
      "source": [
        "#Melhores parâmetros \n",
        "print(mlp.best_params_)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'solver': 'adam', 'max_iter': 1000, 'hidden_layer_sizes': 50, 'activation': 'logistic'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcoFYrwwZXuD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3aa366b-c10e-4c30-933f-ab1766a97ba6"
      },
      "source": [
        "#melhor score\n",
        "print(round(mlp.best_score_,3))"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VX9XGa2zGvs4",
        "colab_type": "text"
      },
      "source": [
        "**Grid search**\n",
        "\n",
        "*   monta um espaço de soluções reduzido como um reticulado\n",
        "*   testa todas as soluções, guardando a melhor\n",
        "# Nova seção"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgNJ11OuZhDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE_ZuwqzZj9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = GridSearchCV(MLPClassifier(),param_grid,cv=5,scoring='accuracy')"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiIqRKJJZnI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c5e5f382-1ae5-4d5d-d7e0-e732b0305e4b"
      },
      "source": [
        "mlp.fit(X,y)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
              "                                     batch_size='auto', beta_1=0.9,\n",
              "                                     beta_2=0.999, early_stopping=False,\n",
              "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
              "                                     learning_rate='constant',\n",
              "                                     learning_rate_init=0.001, max_fun=15000,\n",
              "                                     max_iter=200, momentum=0.9,\n",
              "                                     n_iter_no_change=10,\n",
              "                                     nesterovs_momentum=True, power_t=0.5,\n",
              "                                     random_state...\n",
              "                                     solver='adam', tol=0.0001,\n",
              "                                     validation_fraction=0.1, verbose=False,\n",
              "                                     warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid=[{'activation': ['identity', 'logistic', 'tanh',\n",
              "                                         'relu'],\n",
              "                          'hidden_layer_sizes': [10, 50, 100, (50, 10),\n",
              "                                                 (100, 50)],\n",
              "                          'max_iter': [500, 1000, 2000],\n",
              "                          'solver': ['lbfgs', 'sgd', 'adam']}],\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wWXjYzDbtKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "93e646e6-d9cb-4890-e446-dedec9741ace"
      },
      "source": [
        "#melhores parâmetros\n",
        "print(mlp.best_params_)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'activation': 'logistic', 'hidden_layer_sizes': 50, 'max_iter': 2000, 'solver': 'adam'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tYgNXkfbzaK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62485b25-7754-4d8a-f41d-3311c2855889"
      },
      "source": [
        "#melhor score\n",
        "print(mlp.best_score_)"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8379234972677596\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh8VVEaQJQHe",
        "colab_type": "text"
      },
      "source": [
        "**Usando Grid search conseguimos obter um score maior que o Random search, principalmente porque testa todas as soluções, guardando a melhor.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9STKvh34b1MZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8c9ef7bf-c9e5-44ff-dbdc-ad86b9121344"
      },
      "source": [
        "#resultado em cada uma das configurações\n",
        "mlp.cv_results_"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([5.23214340e-03, 4.06405926e-02, 2.57492399e-01, 3.63063812e-03,\n",
              "        2.72419453e-02, 1.86798000e-01, 3.91411781e-03, 3.93228531e-02,\n",
              "        1.50595808e-01, 6.62846565e-03, 8.31882477e-02, 1.55654860e-01,\n",
              "        6.40335083e-03, 6.40216827e-02, 1.55280113e-01, 6.69689178e-03,\n",
              "        7.54848480e-02, 1.79851246e-01, 8.33849907e-03, 7.15077877e-02,\n",
              "        1.62787628e-01, 1.85035133e-01, 7.03647614e-02, 1.23386669e-01,\n",
              "        8.31270218e-03, 7.90893555e-02, 1.50623322e-01, 7.47642517e-03,\n",
              "        6.56735897e-02, 8.77867699e-02, 5.10106087e-03, 5.37568569e-02,\n",
              "        1.00363779e-01, 5.02567291e-03, 4.74741459e-02, 9.67567921e-02,\n",
              "        3.10285091e-02, 1.32942343e-01, 1.26955366e-01, 1.63892746e-02,\n",
              "        1.26490116e-01, 1.50290728e-01, 1.57694340e-02, 1.32147074e-01,\n",
              "        1.15845394e-01, 1.50852871e-01, 2.80463839e-01, 3.51235294e-01,\n",
              "        8.98170471e-02, 1.44538641e-01, 4.02366686e-01, 4.59833241e-01,\n",
              "        1.47267723e-01, 4.15061235e-01, 7.12951469e-01, 4.61104488e-01,\n",
              "        5.97767782e-01, 1.34951553e+00, 5.52582550e-01, 6.38381243e-01,\n",
              "        1.93718643e+00, 4.76606131e-01, 5.87478733e-01, 1.11936946e+00,\n",
              "        6.82607555e-01, 7.46902609e-01, 2.21555610e+00, 5.39532948e-01,\n",
              "        6.47407293e-01, 4.42639408e+00, 5.08030224e-01, 5.89818335e-01,\n",
              "        5.76170778e-01, 9.57871437e-02, 5.69237947e-01, 9.80021238e-01,\n",
              "        9.02812958e-02, 4.80562878e-01, 1.96869278e+00, 1.11188841e-01,\n",
              "        5.14381933e-01, 1.95151644e+00, 5.13111734e-01, 1.05990477e+00,\n",
              "        4.23368931e+00, 2.83305168e-01, 8.97088051e-01, 7.10414581e+00,\n",
              "        8.60245800e-01, 9.79728079e-01, 1.40581703e-01, 4.58258629e-02,\n",
              "        2.53974342e-01, 2.10085726e-01, 4.23845768e-02, 2.66023779e-01,\n",
              "        2.94304705e-01, 7.56972313e-02, 1.88002586e-01, 5.89010763e-01,\n",
              "        1.47069740e-01, 8.03194618e-01, 9.43197298e-01, 1.40045357e-01,\n",
              "        7.41496468e-01, 2.08718882e+00, 1.59077644e-01, 6.48894644e-01,\n",
              "        8.75995350e-01, 1.66458225e-01, 9.00538826e-01, 2.13309793e+00,\n",
              "        2.79096794e-01, 1.35025187e+00, 3.28591752e+00, 1.90882874e-01,\n",
              "        7.42087936e-01, 5.32677078e-01, 1.36517239e-01, 4.76545811e-01,\n",
              "        8.55428314e-01, 1.56222343e-01, 3.52089310e-01, 1.80985708e+00,\n",
              "        1.43742371e-01, 4.64763927e-01, 1.99271874e+00, 4.18214369e-01,\n",
              "        1.08620148e+00, 3.98400660e+00, 3.49959612e-01, 1.02346582e+00,\n",
              "        6.77680078e+00, 3.05790901e-01, 8.16209841e-01, 1.32595062e-02,\n",
              "        7.79561520e-02, 3.45564651e-01, 4.53796387e-03, 4.19779301e-02,\n",
              "        4.73331833e-01, 7.19841480e-02, 3.61130714e-02, 3.57273245e-01,\n",
              "        6.86407089e-03, 7.61048317e-02, 3.69834232e-01, 1.00592041e-01,\n",
              "        1.13888121e-01, 2.90420341e-01, 7.17363358e-03, 4.96716499e-02,\n",
              "        3.62563467e-01, 1.57829094e-01, 1.40797949e-01, 2.84105778e-01,\n",
              "        2.31465340e-02, 1.00816870e-01, 3.05217361e-01, 5.20800591e-02,\n",
              "        5.58925152e-02, 3.23924160e-01, 1.20625639e-01, 6.40113831e-02,\n",
              "        2.21070576e-01, 2.18169451e-01, 1.14746332e-01, 2.53508472e-01,\n",
              "        2.86836147e-02, 1.50256300e-01, 2.19735527e-01, 1.77079678e-02,\n",
              "        2.81737280e-01, 4.09647226e-01, 6.80919456e-01, 1.57800007e-01,\n",
              "        4.99507856e-01, 1.85602188e-02, 1.35900784e-01, 3.72575426e-01]),\n",
              " 'mean_score_time': array([0.00145893, 0.00145645, 0.00149612, 0.00118437, 0.00137763,\n",
              "        0.00137644, 0.00116854, 0.00136676, 0.00136251, 0.00184093,\n",
              "        0.00195222, 0.00184026, 0.00167198, 0.00179596, 0.00186605,\n",
              "        0.00184236, 0.00187359, 0.0018281 , 0.00182786, 0.00187087,\n",
              "        0.00192251, 0.00189652, 0.00189033, 0.00186787, 0.0017674 ,\n",
              "        0.00187507, 0.00186749, 0.00183215, 0.00174322, 0.00143037,\n",
              "        0.0012991 , 0.00169511, 0.00143461, 0.0012547 , 0.00141521,\n",
              "        0.00150905, 0.00194426, 0.00206585, 0.00214119, 0.0019907 ,\n",
              "        0.00202751, 0.00201597, 0.00194998, 0.00197406, 0.00204449,\n",
              "        0.00176005, 0.00181823, 0.00188169, 0.00140152, 0.00142088,\n",
              "        0.00139112, 0.00165157, 0.00156097, 0.00144706, 0.00218215,\n",
              "        0.00195088, 0.00216346, 0.00200448, 0.00201688, 0.00198231,\n",
              "        0.00201502, 0.00194416, 0.00200267, 0.00212302, 0.0022222 ,\n",
              "        0.00211592, 0.00211101, 0.00222168, 0.00217748, 0.00209332,\n",
              "        0.00228853, 0.00213871, 0.00203729, 0.00155382, 0.0016643 ,\n",
              "        0.00201917, 0.00147772, 0.00158086, 0.00214391, 0.0017942 ,\n",
              "        0.00152578, 0.00240192, 0.00233812, 0.00228848, 0.00239768,\n",
              "        0.00240278, 0.0025219 , 0.00241528, 0.0024509 , 0.00235367,\n",
              "        0.00176349, 0.0013844 , 0.00165009, 0.00164652, 0.00152097,\n",
              "        0.00148106, 0.00152988, 0.00142808, 0.00160527, 0.0026001 ,\n",
              "        0.00207424, 0.00223312, 0.00215826, 0.00197325, 0.00214992,\n",
              "        0.00199647, 0.00195823, 0.0020535 , 0.00239258, 0.0021121 ,\n",
              "        0.00224919, 0.00326376, 0.00305457, 0.00242476, 0.00198522,\n",
              "        0.00213523, 0.00226431, 0.00216928, 0.00148373, 0.00156708,\n",
              "        0.00185442, 0.00156627, 0.00157609, 0.00195575, 0.00152268,\n",
              "        0.00158792, 0.00279064, 0.0023653 , 0.0027967 , 0.00249238,\n",
              "        0.00258937, 0.00280766, 0.0024581 , 0.00234966, 0.00248246,\n",
              "        0.00175862, 0.00148997, 0.00172844, 0.00127034, 0.00143118,\n",
              "        0.00145316, 0.00129342, 0.00165172, 0.00142789, 0.00181379,\n",
              "        0.00190258, 0.00192866, 0.00202255, 0.00194159, 0.00196714,\n",
              "        0.00199232, 0.00191755, 0.00199122, 0.00200882, 0.00203714,\n",
              "        0.00211272, 0.00203266, 0.00207405, 0.00202565, 0.0019587 ,\n",
              "        0.00206037, 0.00200491, 0.00170326, 0.00174098, 0.00151563,\n",
              "        0.00155411, 0.00162339, 0.0017365 , 0.0015501 , 0.00169015,\n",
              "        0.00149865, 0.00229144, 0.00226631, 0.00220222, 0.00214143,\n",
              "        0.00217199, 0.00220881, 0.00207224, 0.0021174 , 0.0021615 ]),\n",
              " 'mean_test_score': array([0.45540984, 0.68655738, 0.8347541 , 0.47180328, 0.69961749,\n",
              "        0.79486339, 0.45540984, 0.70939891, 0.64103825, 0.46196721,\n",
              "        0.71601093, 0.79202186, 0.4557377 , 0.68666667, 0.73300546,\n",
              "        0.45540984, 0.71617486, 0.79863388, 0.45540984, 0.70278689,\n",
              "        0.82142077, 0.54065574, 0.67650273, 0.77551913, 0.45540984,\n",
              "        0.67994536, 0.79513661, 0.47874317, 0.69311475, 0.76568306,\n",
              "        0.45540984, 0.68972678, 0.69213115, 0.45540984, 0.70295082,\n",
              "        0.71989071, 0.47180328, 0.67661202, 0.72568306, 0.45540984,\n",
              "        0.69622951, 0.7689071 , 0.49120219, 0.70622951, 0.75562842,\n",
              "        0.72306011, 0.64710383, 0.82491803, 0.59699454, 0.60688525,\n",
              "        0.8215847 , 0.74568306, 0.64032787, 0.82814208, 0.80825137,\n",
              "        0.66661202, 0.82480874, 0.74224044, 0.67655738, 0.8115847 ,\n",
              "        0.69322404, 0.68655738, 0.82808743, 0.75224044, 0.67983607,\n",
              "        0.81180328, 0.73579235, 0.68983607, 0.82486339, 0.72939891,\n",
              "        0.67994536, 0.79519126, 0.68322404, 0.54459016, 0.81808743,\n",
              "        0.70262295, 0.54459016, 0.78874317, 0.70622951, 0.54459016,\n",
              "        0.79196721, 0.66688525, 0.56098361, 0.8247541 , 0.66377049,\n",
              "        0.54459016, 0.82147541, 0.66054645, 0.57459016, 0.8084153 ,\n",
              "        0.66016393, 0.56092896, 0.69628415, 0.68333333, 0.57098361,\n",
              "        0.68377049, 0.74918033, 0.59437158, 0.68338798, 0.75535519,\n",
              "        0.62666667, 0.80825137, 0.77202186, 0.64349727, 0.77874317,\n",
              "        0.75229508, 0.64994536, 0.78191257, 0.78202186, 0.67338798,\n",
              "        0.80185792, 0.75568306, 0.64704918, 0.79857923, 0.73901639,\n",
              "        0.64032787, 0.78546448, 0.75262295, 0.68677596, 0.76562842,\n",
              "        0.71      , 0.66972678, 0.7689071 , 0.73256831, 0.63704918,\n",
              "        0.80185792, 0.7357377 , 0.68016393, 0.75245902, 0.71590164,\n",
              "        0.65677596, 0.74256831, 0.67994536, 0.67661202, 0.76557377,\n",
              "        0.53409836, 0.63704918, 0.76901639, 0.47540984, 0.58786885,\n",
              "        0.81825137, 0.51874317, 0.59021858, 0.70327869, 0.50131148,\n",
              "        0.67005464, 0.80513661, 0.62622951, 0.64661202, 0.80174863,\n",
              "        0.45540984, 0.6304918 , 0.77863388, 0.54721311, 0.68344262,\n",
              "        0.80174863, 0.51114754, 0.67661202, 0.78868852, 0.5242623 ,\n",
              "        0.66349727, 0.7852459 , 0.53409836, 0.60043716, 0.81174863,\n",
              "        0.60060109, 0.5442623 , 0.69885246, 0.57775956, 0.53125683,\n",
              "        0.78513661, 0.45540984, 0.67994536, 0.74584699, 0.52874317,\n",
              "        0.64311475, 0.75568306, 0.45540984, 0.6863388 , 0.78540984]),\n",
              " 'param_activation': masked_array(data=['identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'identity', 'identity', 'identity',\n",
              "                    'identity', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'logistic', 'logistic',\n",
              "                    'logistic', 'logistic', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh',\n",
              "                    'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'tanh', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu', 'relu', 'relu', 'relu', 'relu', 'relu',\n",
              "                    'relu', 'relu'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_hidden_layer_sizes': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50, 50, 50, 50,\n",
              "                    50, 50, 50, 50, 100, 100, 100, 100, 100, 100, 100, 100,\n",
              "                    100, (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), 10, 10, 10, 10, 10,\n",
              "                    10, 10, 10, 10, 50, 50, 50, 50, 50, 50, 50, 50, 50,\n",
              "                    100, 100, 100, 100, 100, 100, 100, 100, 100, (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), 10, 10, 10, 10, 10, 10, 10, 10,\n",
              "                    10, 50, 50, 50, 50, 50, 50, 50, 50, 50, 100, 100, 100,\n",
              "                    100, 100, 100, 100, 100, 100, (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), 10, 10, 10, 10, 10, 10, 10, 10, 10, 50, 50,\n",
              "                    50, 50, 50, 50, 50, 50, 50, 100, 100, 100, 100, 100,\n",
              "                    100, 100, 100, 100, (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (50, 10), (50, 10), (50, 10), (50, 10),\n",
              "                    (50, 10), (100, 50), (100, 50), (100, 50), (100, 50),\n",
              "                    (100, 50), (100, 50), (100, 50), (100, 50), (100, 50)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_max_iter': masked_array(data=[500, 500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500,\n",
              "                    500, 500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500,\n",
              "                    500, 1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000, 500, 500, 500,\n",
              "                    1000, 1000, 1000, 2000, 2000, 2000],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
              "                    'lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam'],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'identity',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'logistic',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'tanh',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 10,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 50,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': 100,\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (50, 10),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 500,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 1000,\n",
              "   'solver': 'adam'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'lbfgs'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'sgd'},\n",
              "  {'activation': 'relu',\n",
              "   'hidden_layer_sizes': (100, 50),\n",
              "   'max_iter': 2000,\n",
              "   'solver': 'adam'}],\n",
              " 'rank_test_score': array([170,  93,   1, 166,  82,  28, 170,  75, 128, 168,  72,  29, 169,\n",
              "         92,  65, 170,  71,  24, 170,  80,  10, 154, 111,  41, 170, 103,\n",
              "         27, 164,  87,  46, 170,  90,  88, 170,  79,  70, 166, 108,  68,\n",
              "        170,  85,  44, 163,  76,  51,  69, 123,   4, 139, 136,   8,  59,\n",
              "        129,   2,  17, 116,   6,  61, 110,  15,  86,  93,   3,  56, 106,\n",
              "         13,  63,  89,   5,  67, 103,  26, 100, 149,  12,  81, 149,  31,\n",
              "         76, 149,  30, 115, 146,   7, 117, 149,   9, 119, 144,  16, 120,\n",
              "        147,  84,  99, 145,  96,  57, 140,  98,  52, 134,  17,  42, 126,\n",
              "         39,  55, 122,  38,  37, 112,  20,  49, 124,  25,  62, 130,  33,\n",
              "         53,  91,  47,  74, 114,  44,  66, 132,  20,  64, 101,  54,  73,\n",
              "        121,  60, 102, 108,  48, 155, 131,  43, 165, 142,  11, 160, 141,\n",
              "         78, 162, 113,  19, 135, 125,  22, 170, 133,  40, 148,  97,  22,\n",
              "        161, 107,  32, 159, 118,  35, 155, 138,  14, 137, 153,  83, 143,\n",
              "        157,  36, 170, 103,  58, 158, 127,  49, 170,  95,  34], dtype=int32),\n",
              " 'split0_test_score': array([0.45901639, 0.6557377 , 0.81967213, 0.54098361, 0.6557377 ,\n",
              "        0.83606557, 0.45901639, 0.67213115, 0.80327869, 0.49180328,\n",
              "        0.68852459, 0.80327869, 0.36065574, 0.6557377 , 0.42622951,\n",
              "        0.45901639, 0.68852459, 0.80327869, 0.45901639, 0.70491803,\n",
              "        0.83606557, 0.45901639, 0.59016393, 0.81967213, 0.45901639,\n",
              "        0.62295082, 0.83606557, 0.45901639, 0.62295082, 0.75409836,\n",
              "        0.45901639, 0.6557377 , 0.81967213, 0.45901639, 0.67213115,\n",
              "        0.81967213, 0.54098361, 0.67213115, 0.67213115, 0.45901639,\n",
              "        0.6557377 , 0.75409836, 0.54098361, 0.67213115, 0.72131148,\n",
              "        0.78688525, 0.60655738, 0.81967213, 0.54098361, 0.54098361,\n",
              "        0.78688525, 0.81967213, 0.59016393, 0.81967213, 0.86885246,\n",
              "        0.62295082, 0.81967213, 0.70491803, 0.62295082, 0.78688525,\n",
              "        0.60655738, 0.62295082, 0.85245902, 0.73770492, 0.63934426,\n",
              "        0.7704918 , 0.75409836, 0.62295082, 0.83606557, 0.72131148,\n",
              "        0.62295082, 0.72131148, 0.63934426, 0.54098361, 0.83606557,\n",
              "        0.83606557, 0.54098361, 0.7704918 , 0.57377049, 0.54098361,\n",
              "        0.83606557, 0.62295082, 0.62295082, 0.85245902, 0.62295082,\n",
              "        0.54098361, 0.85245902, 0.55737705, 0.54098361, 0.78688525,\n",
              "        0.49180328, 0.6557377 , 0.72131148, 0.80327869, 0.57377049,\n",
              "        0.57377049, 0.85245902, 0.57377049, 0.68852459, 0.80327869,\n",
              "        0.59016393, 0.81967213, 0.80327869, 0.52459016, 0.7704918 ,\n",
              "        0.72131148, 0.60655738, 0.78688525, 0.78688525, 0.60655738,\n",
              "        0.81967213, 0.78688525, 0.59016393, 0.85245902, 0.78688525,\n",
              "        0.62295082, 0.83606557, 0.80327869, 0.59016393, 0.80327869,\n",
              "        0.62295082, 0.62295082, 0.78688525, 0.67213115, 0.60655738,\n",
              "        0.81967213, 0.81967213, 0.59016393, 0.75409836, 0.81967213,\n",
              "        0.63934426, 0.67213115, 0.6557377 , 0.6557377 , 0.78688525,\n",
              "        0.6557377 , 0.54098361, 0.78688525, 0.45901639, 0.49180328,\n",
              "        0.7704918 , 0.45901639, 0.54098361, 0.32786885, 0.45901639,\n",
              "        0.59016393, 0.78688525, 0.81967213, 0.59016393, 0.78688525,\n",
              "        0.45901639, 0.67213115, 0.81967213, 0.60655738, 0.57377049,\n",
              "        0.81967213, 0.45901639, 0.59016393, 0.81967213, 0.80327869,\n",
              "        0.59016393, 0.78688525, 0.45901639, 0.57377049, 0.80327869,\n",
              "        0.45901639, 0.62295082, 0.78688525, 0.45901639, 0.54098361,\n",
              "        0.78688525, 0.45901639, 0.62295082, 0.78688525, 0.45901639,\n",
              "        0.62295082, 0.70491803, 0.45901639, 0.62295082, 0.80327869]),\n",
              " 'split1_test_score': array([0.45901639, 0.62295082, 0.90163934, 0.45901639, 0.67213115,\n",
              "        0.8852459 , 0.45901639, 0.75409836, 0.45901639, 0.45901639,\n",
              "        0.72131148, 0.78688525, 0.45901639, 0.73770492, 0.83606557,\n",
              "        0.45901639, 0.70491803, 0.78688525, 0.45901639, 0.67213115,\n",
              "        0.8852459 , 0.8852459 , 0.70491803, 0.83606557, 0.45901639,\n",
              "        0.62295082, 0.90163934, 0.45901639, 0.67213115, 0.83606557,\n",
              "        0.45901639, 0.68852459, 0.78688525, 0.45901639, 0.67213115,\n",
              "        0.37704918, 0.45901639, 0.6557377 , 0.81967213, 0.45901639,\n",
              "        0.70491803, 0.7704918 , 0.45901639, 0.73770492, 0.81967213,\n",
              "        0.75409836, 0.6557377 , 0.8852459 , 0.81967213, 0.62295082,\n",
              "        0.90163934, 0.6557377 , 0.54098361, 0.90163934, 0.8852459 ,\n",
              "        0.6557377 , 0.8852459 , 0.86885246, 0.6557377 , 0.8852459 ,\n",
              "        0.67213115, 0.6557377 , 0.8852459 , 0.83606557, 0.6557377 ,\n",
              "        0.86885246, 0.75409836, 0.63934426, 0.86885246, 0.7704918 ,\n",
              "        0.63934426, 0.90163934, 0.59016393, 0.54098361, 0.90163934,\n",
              "        0.60655738, 0.54098361, 0.85245902, 0.75409836, 0.54098361,\n",
              "        0.86885246, 0.62295082, 0.54098361, 0.90163934, 0.59016393,\n",
              "        0.54098361, 0.86885246, 0.70491803, 0.54098361, 0.8852459 ,\n",
              "        0.62295082, 0.54098361, 0.59016393, 0.67213115, 0.54098361,\n",
              "        0.75409836, 0.75409836, 0.54098361, 0.72131148, 0.83606557,\n",
              "        0.6557377 , 0.90163934, 0.78688525, 0.67213115, 0.86885246,\n",
              "        0.78688525, 0.68852459, 0.78688525, 0.86885246, 0.60655738,\n",
              "        0.83606557, 0.80327869, 0.52459016, 0.7704918 , 0.67213115,\n",
              "        0.55737705, 0.78688525, 0.7704918 , 0.60655738, 0.81967213,\n",
              "        0.6557377 , 0.68852459, 0.72131148, 0.7704918 , 0.63934426,\n",
              "        0.85245902, 0.72131148, 0.62295082, 0.78688525, 0.72131148,\n",
              "        0.62295082, 0.75409836, 0.6557377 , 0.63934426, 0.80327869,\n",
              "        0.57377049, 0.63934426, 0.72131148, 0.45901639, 0.62295082,\n",
              "        0.8852459 , 0.45901639, 0.63934426, 0.85245902, 0.54098361,\n",
              "        0.6557377 , 0.8852459 , 0.45901639, 0.6557377 , 0.86885246,\n",
              "        0.45901639, 0.6557377 , 0.8852459 , 0.45901639, 0.63934426,\n",
              "        0.85245902, 0.45901639, 0.68852459, 0.80327869, 0.45901639,\n",
              "        0.62295082, 0.83606557, 0.54098361, 0.54098361, 0.85245902,\n",
              "        0.57377049, 0.63934426, 0.72131148, 0.45901639, 0.62295082,\n",
              "        0.83606557, 0.45901639, 0.63934426, 0.75409836, 0.45901639,\n",
              "        0.6557377 , 0.73770492, 0.45901639, 0.67213115, 0.78688525]),\n",
              " 'split2_test_score': array([0.45901639, 0.75409836, 0.85245902, 0.45901639, 0.78688525,\n",
              "        0.81967213, 0.45901639, 0.75409836, 0.42622951, 0.45901639,\n",
              "        0.78688525, 0.80327869, 0.45901639, 0.60655738, 0.83606557,\n",
              "        0.45901639, 0.75409836, 0.81967213, 0.45901639, 0.78688525,\n",
              "        0.85245902, 0.45901639, 0.75409836, 0.68852459, 0.45901639,\n",
              "        0.7704918 , 0.72131148, 0.45901639, 0.7704918 , 0.70491803,\n",
              "        0.45901639, 0.73770492, 0.75409836, 0.45901639, 0.7704918 ,\n",
              "        0.83606557, 0.45901639, 0.68852459, 0.80327869, 0.45901639,\n",
              "        0.7704918 , 0.80327869, 0.63934426, 0.72131148, 0.7704918 ,\n",
              "        0.54098361, 0.60655738, 0.81967213, 0.54098361, 0.7704918 ,\n",
              "        0.83606557, 0.81967213, 0.7704918 , 0.83606557, 0.7704918 ,\n",
              "        0.73770492, 0.85245902, 0.75409836, 0.75409836, 0.85245902,\n",
              "        0.75409836, 0.75409836, 0.83606557, 0.75409836, 0.75409836,\n",
              "        0.81967213, 0.75409836, 0.78688525, 0.83606557, 0.68852459,\n",
              "        0.75409836, 0.81967213, 0.80327869, 0.54098361, 0.83606557,\n",
              "        0.7704918 , 0.54098361, 0.75409836, 0.80327869, 0.54098361,\n",
              "        0.70491803, 0.68852459, 0.54098361, 0.81967213, 0.6557377 ,\n",
              "        0.54098361, 0.83606557, 0.57377049, 0.54098361, 0.80327869,\n",
              "        0.83606557, 0.52459016, 0.80327869, 0.52459016, 0.59016393,\n",
              "        0.54098361, 0.63934426, 0.57377049, 0.57377049, 0.75409836,\n",
              "        0.75409836, 0.80327869, 0.80327869, 0.75409836, 0.73770492,\n",
              "        0.80327869, 0.72131148, 0.85245902, 0.73770492, 0.7704918 ,\n",
              "        0.78688525, 0.70491803, 0.7704918 , 0.80327869, 0.83606557,\n",
              "        0.72131148, 0.73770492, 0.63934426, 0.7704918 , 0.68852459,\n",
              "        0.72131148, 0.7704918 , 0.81967213, 0.78688525, 0.63934426,\n",
              "        0.7704918 , 0.73770492, 0.73770492, 0.72131148, 0.68852459,\n",
              "        0.70491803, 0.80327869, 0.70491803, 0.72131148, 0.73770492,\n",
              "        0.54098361, 0.70491803, 0.78688525, 0.45901639, 0.52459016,\n",
              "        0.86885246, 0.45901639, 0.75409836, 0.83606557, 0.60655738,\n",
              "        0.73770492, 0.78688525, 0.85245902, 0.7704918 , 0.81967213,\n",
              "        0.45901639, 0.52459016, 0.70491803, 0.7704918 , 0.75409836,\n",
              "        0.80327869, 0.73770492, 0.73770492, 0.7704918 , 0.45901639,\n",
              "        0.73770492, 0.80327869, 0.7704918 , 0.75409836, 0.81967213,\n",
              "        0.78688525, 0.45901639, 0.83606557, 0.75409836, 0.45901639,\n",
              "        0.83606557, 0.45901639, 0.75409836, 0.70491803, 0.45901639,\n",
              "        0.78688525, 0.85245902, 0.45901639, 0.80327869, 0.78688525]),\n",
              " 'split3_test_score': array([0.45      , 0.73333333, 0.86666667, 0.45      , 0.71666667,\n",
              "        0.68333333, 0.45      , 0.68333333, 0.81666667, 0.45      ,\n",
              "        0.71666667, 0.83333333, 0.45      , 0.75      , 0.81666667,\n",
              "        0.45      , 0.75      , 0.88333333, 0.45      , 0.73333333,\n",
              "        0.78333333, 0.45      , 0.7       , 0.8       , 0.45      ,\n",
              "        0.75      , 0.78333333, 0.56666667, 0.73333333, 0.85      ,\n",
              "        0.45      , 0.66666667, 0.38333333, 0.45      , 0.76666667,\n",
              "        0.83333333, 0.45      , 0.7       , 0.63333333, 0.45      ,\n",
              "        0.7       , 0.75      , 0.4       , 0.73333333, 0.76666667,\n",
              "        0.85      , 0.71666667, 0.85      , 0.55      , 0.55      ,\n",
              "        0.88333333, 0.75      , 0.71666667, 0.83333333, 0.81666667,\n",
              "        0.71666667, 0.85      , 0.71666667, 0.73333333, 0.83333333,\n",
              "        0.76666667, 0.71666667, 0.86666667, 0.81666667, 0.73333333,\n",
              "        0.85      , 0.71666667, 0.7       , 0.85      , 0.73333333,\n",
              "        0.73333333, 0.85      , 0.7       , 0.55      , 0.83333333,\n",
              "        0.65      , 0.55      , 0.83333333, 0.73333333, 0.55      ,\n",
              "        0.85      , 0.66666667, 0.55      , 0.81666667, 0.71666667,\n",
              "        0.55      , 0.81666667, 0.75      , 0.55      , 0.83333333,\n",
              "        0.65      , 0.53333333, 0.81666667, 0.66666667, 0.6       ,\n",
              "        0.85      , 0.8       , 0.73333333, 0.81666667, 0.73333333,\n",
              "        0.63333333, 0.8       , 0.73333333, 0.7       , 0.8       ,\n",
              "        0.78333333, 0.66666667, 0.81666667, 0.85      , 0.73333333,\n",
              "        0.85      , 0.75      , 0.73333333, 0.85      , 0.75      ,\n",
              "        0.7       , 0.83333333, 0.8       , 0.75      , 0.81666667,\n",
              "        0.83333333, 0.71666667, 0.85      , 0.78333333, 0.66666667,\n",
              "        0.85      , 0.8       , 0.75      , 0.8       , 0.71666667,\n",
              "        0.7       , 0.76666667, 0.7       , 0.73333333, 0.81666667,\n",
              "        0.45      , 0.75      , 0.86666667, 0.55      , 0.75      ,\n",
              "        0.86666667, 0.45      , 0.56666667, 0.8       , 0.45      ,\n",
              "        0.68333333, 0.83333333, 0.45      , 0.55      , 0.81666667,\n",
              "        0.45      , 0.7       , 0.85      , 0.45      , 0.76666667,\n",
              "        0.81666667, 0.45      , 0.75      , 0.81666667, 0.45      ,\n",
              "        0.71666667, 0.76666667, 0.45      , 0.45      , 0.85      ,\n",
              "        0.45      , 0.45      , 0.55      , 0.45      , 0.45      ,\n",
              "        0.75      , 0.45      , 0.75      , 0.73333333, 0.81666667,\n",
              "        0.51666667, 0.76666667, 0.45      , 0.66666667, 0.85      ]),\n",
              " 'split4_test_score': array([0.45      , 0.66666667, 0.73333333, 0.45      , 0.66666667,\n",
              "        0.75      , 0.45      , 0.68333333, 0.7       , 0.45      ,\n",
              "        0.66666667, 0.73333333, 0.55      , 0.68333333, 0.75      ,\n",
              "        0.45      , 0.68333333, 0.7       , 0.45      , 0.61666667,\n",
              "        0.75      , 0.45      , 0.63333333, 0.73333333, 0.45      ,\n",
              "        0.63333333, 0.73333333, 0.45      , 0.66666667, 0.68333333,\n",
              "        0.45      , 0.7       , 0.71666667, 0.45      , 0.63333333,\n",
              "        0.73333333, 0.45      , 0.66666667, 0.7       , 0.45      ,\n",
              "        0.65      , 0.76666667, 0.41666667, 0.66666667, 0.7       ,\n",
              "        0.68333333, 0.65      , 0.75      , 0.53333333, 0.55      ,\n",
              "        0.7       , 0.68333333, 0.58333333, 0.75      , 0.7       ,\n",
              "        0.6       , 0.71666667, 0.66666667, 0.61666667, 0.7       ,\n",
              "        0.66666667, 0.68333333, 0.7       , 0.61666667, 0.61666667,\n",
              "        0.75      , 0.7       , 0.7       , 0.73333333, 0.73333333,\n",
              "        0.65      , 0.68333333, 0.68333333, 0.55      , 0.68333333,\n",
              "        0.65      , 0.55      , 0.73333333, 0.66666667, 0.55      ,\n",
              "        0.7       , 0.73333333, 0.55      , 0.73333333, 0.73333333,\n",
              "        0.55      , 0.73333333, 0.71666667, 0.7       , 0.73333333,\n",
              "        0.7       , 0.55      , 0.55      , 0.75      , 0.55      ,\n",
              "        0.7       , 0.7       , 0.55      , 0.61666667, 0.65      ,\n",
              "        0.5       , 0.71666667, 0.73333333, 0.56666667, 0.71666667,\n",
              "        0.66666667, 0.56666667, 0.66666667, 0.66666667, 0.65      ,\n",
              "        0.71666667, 0.73333333, 0.61666667, 0.71666667, 0.65      ,\n",
              "        0.6       , 0.73333333, 0.75      , 0.71666667, 0.7       ,\n",
              "        0.71666667, 0.55      , 0.66666667, 0.65      , 0.63333333,\n",
              "        0.71666667, 0.6       , 0.7       , 0.7       , 0.63333333,\n",
              "        0.61666667, 0.71666667, 0.68333333, 0.63333333, 0.68333333,\n",
              "        0.45      , 0.55      , 0.68333333, 0.45      , 0.55      ,\n",
              "        0.7       , 0.76666667, 0.45      , 0.7       , 0.45      ,\n",
              "        0.68333333, 0.73333333, 0.55      , 0.66666667, 0.71666667,\n",
              "        0.45      , 0.6       , 0.63333333, 0.45      , 0.68333333,\n",
              "        0.71666667, 0.45      , 0.61666667, 0.73333333, 0.45      ,\n",
              "        0.65      , 0.73333333, 0.45      , 0.68333333, 0.73333333,\n",
              "        0.73333333, 0.55      , 0.6       , 0.76666667, 0.58333333,\n",
              "        0.71666667, 0.45      , 0.63333333, 0.75      , 0.45      ,\n",
              "        0.63333333, 0.71666667, 0.45      , 0.66666667, 0.7       ]),\n",
              " 'std_fit_time': array([1.34094505e-03, 1.69600596e-02, 4.85231244e-02, 1.33917150e-04,\n",
              "        1.35332898e-02, 8.66767287e-02, 2.93014474e-04, 8.97859296e-03,\n",
              "        1.08585805e-01, 6.74937865e-04, 2.08971147e-02, 3.20830616e-02,\n",
              "        2.47188657e-04, 2.41229642e-02, 1.01477398e-01, 3.34655358e-04,\n",
              "        9.41070122e-03, 2.53488705e-02, 4.25766438e-04, 2.51157538e-02,\n",
              "        2.29452512e-02, 3.53615282e-01, 2.18616921e-02, 3.26115038e-02,\n",
              "        2.61624171e-04, 2.65282684e-02, 3.15578225e-02, 2.46762313e-04,\n",
              "        1.09587432e-02, 1.09972859e-02, 1.87869096e-04, 1.38773087e-02,\n",
              "        4.29433475e-02, 2.00180215e-04, 1.17458937e-02, 4.95724706e-02,\n",
              "        3.15853303e-02, 4.10433587e-02, 2.11102021e-02, 1.18347107e-03,\n",
              "        3.32524984e-02, 1.63094291e-02, 8.31422182e-04, 4.42504167e-02,\n",
              "        1.00735780e-02, 9.68666866e-02, 7.46210361e-02, 2.13702928e-02,\n",
              "        1.58864547e-01, 1.48979397e-01, 8.31771016e-02, 3.51290495e-01,\n",
              "        6.57095921e-02, 7.10486555e-02, 2.49060817e-02, 7.60370944e-02,\n",
              "        3.42122030e-02, 2.95122263e-02, 1.08548478e-01, 1.08787715e-01,\n",
              "        1.02400875e+00, 1.00520319e-01, 5.45936307e-02, 2.47215963e-02,\n",
              "        3.88752671e-02, 1.29323372e-01, 5.48274844e-02, 1.19050060e-01,\n",
              "        4.95656234e-02, 1.62798039e-01, 8.17314664e-02, 6.56760253e-02,\n",
              "        2.71743547e-02, 5.37669689e-02, 7.26992166e-02, 2.77794605e-01,\n",
              "        1.90674117e-02, 5.90289562e-02, 9.24408874e-01, 3.28492517e-02,\n",
              "        8.46880579e-02, 2.87459412e-01, 6.36365697e-01, 1.79214944e-01,\n",
              "        8.16085643e-02, 1.12503193e-01, 6.33948538e-02, 2.90985139e+00,\n",
              "        1.36483320e+00, 1.45217419e-01, 5.97435541e-02, 1.83326651e-02,\n",
              "        1.20103859e-01, 1.67315153e-01, 2.41101029e-02, 1.58346750e-01,\n",
              "        2.73989684e-01, 3.31744373e-02, 1.82860301e-01, 1.54565459e-02,\n",
              "        3.58066444e-02, 4.98728169e-02, 2.03551046e-01, 5.92199842e-02,\n",
              "        2.12562757e-01, 8.48326436e-02, 4.85858290e-02, 1.62723416e-01,\n",
              "        3.60031823e-02, 6.09892817e-02, 8.95629034e-02, 9.82870765e-01,\n",
              "        5.08521709e-02, 3.34932168e-01, 4.05403993e-02, 7.31189297e-02,\n",
              "        8.56347016e-02, 2.43092296e-02, 3.45457407e-02, 8.23833307e-02,\n",
              "        2.96731863e-01, 4.21545611e-02, 9.64483005e-02, 2.65661683e-01,\n",
              "        5.83112522e-02, 7.45068428e-02, 7.59447628e-03, 1.63946816e-01,\n",
              "        2.20839741e-01, 8.19292598e-02, 7.71247289e-02, 2.01356198e-01,\n",
              "        2.14017719e+00, 6.68592281e-02, 1.09929644e-01, 1.49211110e-02,\n",
              "        6.85450695e-02, 4.67763049e-02, 8.25266887e-04, 3.67009310e-02,\n",
              "        1.47565966e-01, 1.35928798e-01, 2.92994996e-02, 1.90911016e-01,\n",
              "        3.08514084e-04, 3.90658017e-02, 7.82313198e-02, 1.17520596e-01,\n",
              "        6.25689082e-02, 6.54606613e-02, 5.09844284e-04, 3.15510386e-02,\n",
              "        1.69659057e-01, 2.95174473e-01, 4.90455048e-02, 9.53767815e-02,\n",
              "        2.86517441e-02, 2.44223192e-02, 7.66940091e-02, 8.39723421e-02,\n",
              "        1.85806754e-02, 9.90458951e-02, 2.27757053e-01, 3.37128706e-02,\n",
              "        3.64972762e-02, 2.65919808e-01, 7.36562783e-02, 1.18004336e-01,\n",
              "        3.00548153e-02, 8.68050274e-02, 5.31032710e-02, 1.96661023e-03,\n",
              "        8.33524245e-02, 2.94265941e-01, 1.32989324e+00, 2.43455373e-02,\n",
              "        1.36393380e-01, 2.73227423e-03, 3.25042960e-02, 1.12881930e-01]),\n",
              " 'std_score_time': array([2.82718734e-04, 1.23727748e-04, 2.37235155e-04, 2.72739183e-05,\n",
              "        2.16970863e-05, 1.92700037e-05, 4.91716919e-05, 2.55669217e-05,\n",
              "        1.70167409e-05, 5.53148779e-05, 7.76000285e-06, 1.81965708e-05,\n",
              "        3.47497512e-05, 4.65350071e-06, 3.85077818e-05, 1.83289691e-04,\n",
              "        5.57713192e-05, 5.11965470e-05, 3.59592130e-05, 2.32699465e-05,\n",
              "        4.78675636e-05, 8.45593229e-05, 1.15691740e-05, 2.75876568e-05,\n",
              "        1.29292353e-05, 7.82971260e-05, 3.08828547e-05, 8.00411474e-05,\n",
              "        4.41038300e-04, 3.91051825e-05, 3.51145810e-05, 5.89519747e-04,\n",
              "        9.57307333e-05, 2.49721582e-05, 3.43400231e-05, 2.45190742e-04,\n",
              "        2.66766419e-05, 1.90562254e-04, 3.25307640e-04, 6.21204812e-05,\n",
              "        7.34333868e-05, 7.24311719e-05, 4.38553851e-05, 4.60071014e-05,\n",
              "        5.38111103e-05, 2.72557442e-04, 2.49969909e-04, 2.70028786e-04,\n",
              "        2.68134044e-04, 6.07773058e-05, 3.97017837e-05, 2.72478388e-04,\n",
              "        2.34211248e-04, 4.97235308e-05, 2.53768937e-04, 2.74968469e-05,\n",
              "        2.51420656e-04, 1.02624463e-04, 7.13804043e-05, 2.85041751e-05,\n",
              "        3.13893611e-05, 1.16903901e-05, 4.10455155e-05, 3.10181014e-05,\n",
              "        2.30233285e-04, 2.75772701e-05, 7.19482964e-05, 1.90257405e-04,\n",
              "        1.03618810e-04, 4.16442941e-05, 2.78377574e-04, 4.58881385e-05,\n",
              "        4.46188125e-05, 1.02523249e-04, 2.08447966e-04, 8.24947577e-05,\n",
              "        2.59948423e-05, 6.90694303e-05, 3.00122588e-04, 5.09131443e-04,\n",
              "        5.40907813e-05, 1.57223964e-04, 7.26909119e-05, 2.55464590e-05,\n",
              "        7.99769216e-05, 5.63592474e-05, 3.67456252e-04, 5.04737481e-05,\n",
              "        2.17827982e-04, 5.60197418e-05, 3.15015481e-04, 2.80875301e-05,\n",
              "        2.86881974e-04, 2.87631439e-04, 8.64191019e-05, 1.78362531e-04,\n",
              "        1.66612826e-04, 2.56773157e-05, 2.42060831e-04, 6.27122312e-04,\n",
              "        1.86051875e-04, 2.25795893e-04, 3.49184064e-04, 3.80187861e-05,\n",
              "        1.40114410e-04, 2.05456477e-04, 9.16699563e-05, 7.85013583e-05,\n",
              "        2.62712150e-04, 7.85928900e-05, 7.20103683e-05, 1.37311896e-03,\n",
              "        1.14224860e-03, 2.78105412e-04, 7.21673151e-05, 7.35355564e-05,\n",
              "        3.85862333e-05, 1.85639914e-04, 2.70629348e-05, 4.60856145e-05,\n",
              "        1.95233170e-04, 9.32653257e-05, 3.56939289e-05, 2.89485125e-04,\n",
              "        9.03211397e-05, 5.59164309e-05, 1.62586326e-04, 6.92313366e-05,\n",
              "        5.21046999e-04, 1.49919256e-04, 2.38054694e-04, 5.63778900e-04,\n",
              "        2.50756507e-04, 4.95521686e-05, 2.67982483e-05, 8.99075671e-05,\n",
              "        1.88678239e-04, 2.90180646e-04, 2.21004635e-05, 2.26542318e-05,\n",
              "        6.76179638e-05, 7.56677620e-05, 3.46309183e-04, 2.75890579e-05,\n",
              "        7.01702130e-05, 2.57151873e-05, 3.89058214e-05, 2.41965020e-04,\n",
              "        8.02447094e-05, 6.18752760e-05, 9.92397224e-05, 1.63780896e-05,\n",
              "        7.02433736e-05, 4.23045133e-05, 7.71805684e-05, 2.04942847e-04,\n",
              "        1.19424207e-04, 6.75899473e-05, 4.83846173e-05, 2.95310453e-05,\n",
              "        1.79209805e-04, 5.26350040e-05, 2.63071670e-04, 4.74842223e-04,\n",
              "        3.61680277e-05, 6.11692312e-05, 1.85777923e-04, 2.05669247e-04,\n",
              "        7.62262044e-05, 3.29042206e-04, 4.69635946e-05, 6.72397882e-05,\n",
              "        2.00462341e-04, 9.78357139e-05, 6.06064342e-05, 4.76524728e-05,\n",
              "        9.37831656e-05, 1.79556893e-05, 1.92231032e-05, 8.77959382e-05]),\n",
              " 'std_test_score': array([0.00441711, 0.04927689, 0.05712994, 0.0348244 , 0.04831775,\n",
              "        0.07061695, 0.00441711, 0.03672546, 0.16728332, 0.01545337,\n",
              "        0.04060061, 0.03295694, 0.05996729, 0.05291734, 0.15661563,\n",
              "        0.00441711, 0.03017334, 0.059169  , 0.00441711, 0.05721298,\n",
              "        0.04858615, 0.17234226, 0.05779034, 0.05578954, 0.00441711,\n",
              "        0.06599356, 0.06697332, 0.04410022, 0.05228295, 0.06733664,\n",
              "        0.00441711, 0.02862136, 0.15814111, 0.00441711, 0.05543968,\n",
              "        0.17552389, 0.0348244 , 0.01577106, 0.07336338, 0.00441711,\n",
              "        0.04331593, 0.01879209, 0.0886945 , 0.03059641, 0.04175293,\n",
              "        0.10571738, 0.04052147, 0.04457871, 0.11146389, 0.08699436,\n",
              "        0.07268869, 0.06774224, 0.08764056, 0.04831046, 0.06755089,\n",
              "        0.05295542, 0.0579187 , 0.06918033, 0.05679812, 0.06423534,\n",
              "        0.05960003, 0.04576985, 0.06605977, 0.07716524, 0.05401395,\n",
              "        0.04539119, 0.02303134, 0.05770306, 0.04731938, 0.02628955,\n",
              "        0.05318363, 0.08112327, 0.07110581, 0.00441711, 0.07213661,\n",
              "        0.08623231, 0.00441711, 0.04615543, 0.07944205, 0.00441711,\n",
              "        0.07383676, 0.04181895, 0.03124489, 0.05500526, 0.05437957,\n",
              "        0.00441711, 0.0473489 , 0.07911289, 0.06280208, 0.05030125,\n",
              "        0.11167966, 0.04814143, 0.1088363 , 0.09426982, 0.0226182 ,\n",
              "        0.11430639, 0.07450635, 0.07067997, 0.08449321, 0.06387031,\n",
              "        0.08307262, 0.05887668, 0.03215121, 0.08519026, 0.05324895,\n",
              "        0.05109088, 0.05599811, 0.06247515, 0.07410134, 0.0670854 ,\n",
              "        0.04751189, 0.03563093, 0.09147489, 0.05112296, 0.06961058,\n",
              "        0.06152763, 0.04439042, 0.05994802, 0.07438814, 0.05864343,\n",
              "        0.0719798 , 0.07646279, 0.06662554, 0.05905215, 0.01913786,\n",
              "        0.05183987, 0.07721573, 0.06317413, 0.0378685 , 0.0606056 ,\n",
              "        0.03805979, 0.04479221, 0.02102057, 0.04222089, 0.04904383,\n",
              "        0.07818246, 0.08267465, 0.06291504, 0.03745821, 0.09185215,\n",
              "        0.07163399, 0.12401092, 0.10189204, 0.19503099, 0.06277768,\n",
              "        0.04799314, 0.05105779, 0.17517297, 0.07530197, 0.05001317,\n",
              "        0.00441711, 0.06220528, 0.09454064, 0.12653423, 0.07195989,\n",
              "        0.04551181, 0.11335043, 0.06376012, 0.03271376, 0.13956646,\n",
              "        0.05574537, 0.03449815, 0.12305416, 0.10710809, 0.04336815,\n",
              "        0.1383954 , 0.07926869, 0.10863745, 0.1492003 , 0.06787594,\n",
              "        0.04714508, 0.00441711, 0.05911993, 0.02683744, 0.14400409,\n",
              "        0.08639522, 0.0527424 , 0.00441711, 0.06110453, 0.04856002])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    }
  ]
}